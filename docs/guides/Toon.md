Meet TOON - the new language for talking to LLMs efficiently.

If JSON was built for humans, TOON (Token-Oriented Object Notation) is built for machines that think in tokens.

 And in the world of AI, where every token has a cost, in speed, compute, and cash, that difference matters.

 What is TOON?
 A compact, deterministic format for structured data that eliminates redundant key names and expresses information in a tabular, columnar way that LLMs parse more reliably and cheaply.


 Think of it as ‚ÄúCSV for reasoning‚Äù clean, predictable, and made for token efficiency.

üß© Let‚Äôs see it in action
------------------------------

Instead of this classic JSON bloat:

{
 "orders": [
 { "order_id": 101, "customer": "Emma", "total": 124.75, "status": "delivered" },
 { "order_id": 102, "customer": "Raj", "total": 89.50, "status": "pending" },
 { "order_id": 103, "customer": "Ava", "total": 42.10, "status": "cancelled" }
 ]
}
------------------------------

TOON encodes it like this:

orders[3]{order_id,customer,total,status}:
 101,Emma,124.75,delivered
 102,Raj,89.50,pending
 103,Ava,42.10,cancelled
------------------------------

That‚Äôs ~45% fewer tokens, and it scales even better for larger datasets.

Why TOON is brilliant

Token-efficient: 30‚Äì60% reduction in prompt size
LLM-friendly: Consistent, columnar layout makes pattern recognition easier for models
Low-friction: Convert from JSON, use it in your prompt, decode back when needed
Composable: Works beautifully inside RAG pipelines, multi-agent systems, and autonomous data flows

As prompts evolve from ‚Äúchatting with AI‚Äù to building reasoning pipelines, we need formats that keep up, not just humans reading data, but machines understanding context.

 TOON is a reminder that real innovation isn‚Äôt always about bigger models.

 Sometimes, it‚Äôs about rethinking the invisible layer that connects them all ‚Äî the structure of information itself.

Smaller prompts. Faster reasoning. Smarter agents.
