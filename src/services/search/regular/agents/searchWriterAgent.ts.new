import { AgentResponse, ResearchResult, ArticleResult, SearchResult } from '../../../../common/types';
import { logger } from '../../../../utils/logger.ts';

const MAX_RETRIES = 3;
const INITIAL_RETRY_DELAY = 1000; // 1 second

export class SearchWriterAgent {
  private readonly netlifyFunctionUrl: string;
  private readonly defaultModel: string = 'gpt-4o-mini';

  constructor() {
    this.netlifyFunctionUrl = '/.netlify/functions/fetch-openai';
    logger.info('SearchWriterAgent: Initialized with OpenAI Responses API integration');
  }

  /**
   * Provides fallback article data if article generation fails.
   */
  private getFallbackData(query: string): ArticleResult {
    return {
      content: 'We apologize, but we are experiencing high traffic at the moment. Please try your search again in a few minutes.',
      followUpQuestions: [
        `What specific information would be most valuable about ${query}?`,
        `How can I explore different aspects of ${query}?`,
        `What current developments should I know about ${query}?`,
        `Where can I find expert insights on ${query}?`,
        `What practical applications relate to ${query}?`
      ],
      citations: []
    };
  }

  /**
   * Generates default follow-up questions based on the query
   */
  private getDefaultFollowUpQuestions(query: string): string[] {
    return [
      `What are the latest developments in ${query}?`,
      `How does ${query} compare to similar technologies?`,
      `What are the benefits of ${query}?`,
      `What are the challenges associated with ${query}?`,
      `Where can I learn more about ${query}?`
    ];
  }

  /**
   * Calls the OpenAI Responses API via Netlify function with retry logic
   */
  private async callOpenAIViaNetlify(
    messages: Array<{ role: string; content: string }>,
    model: string = this.defaultModel,
    retryCount: number = 0
  ): Promise<string> {
    const currentRetry = typeof retryCount === 'number' ? retryCount : 0;
    try {
      logger.debug('Calling OpenAI Responses API via Netlify function', { 
        model, 
        messageCount: messages.length,
        retryCount 
      });

      // Format the messages into a single input string for the Responses API
      const systemMessage = messages.find(m => m.role === 'system')?.content || '';
      const userMessage = messages.find(m => m.role === 'user')?.content || '';
      
      // Create input for the Responses API
      const input = `${systemMessage}\n\n${userMessage}`;

      logger.debug('Sending request to fetch-openai', { 
        url: this.netlifyFunctionUrl,
        inputLength: input.length 
      });

      const response = await fetch(this.netlifyFunctionUrl, {
        method: 'POST',
        headers: { 
          'Content-Type': 'application/json',
          'Accept': 'application/json'
        },
        body: JSON.stringify({ 
          input,
          model,
          temperature: 0.3,
          max_completion_tokens: 2000,
          response_format: { type: 'json_object' },
          reasoning_effort: 'medium'
        })
      });

      if (!response.ok) {
        const errorText = await response.text();
        logger.error('Error from fetch-openai function', {
          status: response.status,
          statusText: response.statusText,
          errorText
        });
        throw new Error(`HTTP error! status: ${response.status}, body: ${errorText}`);
      }

      const data = await response.json();
      logger.debug('Received response from fetch-openai', { 
        success: data.success,
        hasContent: !!data.content,
        hasError: !!data.error
      });

      // Handle error response
      if (data.error) {
        logger.error('API error in response', { error: data.error });
        throw new Error(`API Error: ${data.error}`);
      }

      if (!data.success || !data.content) {
        throw new Error('No content in response');
      }

      // Return the content from the Responses API
      return data.content;

    } catch (error: unknown) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      
      if (currentRetry < MAX_RETRIES) {
        const delay = INITIAL_RETRY_DELAY * Math.pow(2, currentRetry);
        logger.warn(`Retry ${currentRetry + 1}/${MAX_RETRIES} after error:`, {
          error: errorMessage
        });
        await new Promise(resolve => setTimeout(resolve, delay));
        return this.callOpenAIViaNetlify(messages, model, currentRetry + 1);
      }
      
      logger.error('Max retries reached, returning fallback response', {
        error: errorMessage,
        query: messages.find(m => m.role === 'user')?.content?.substring(0, 100) || 'No query'
      });
      
      // Return a fallback response that matches the expected format
      return JSON.stringify({
        content: 'Sorry, I encountered an error while generating the response. Please try again later.',
        followUpQuestions: [
          'What specific information would be most valuable about this topic?',
          'How can I explore different aspects of this subject?',
          'What current developments should I know about?',
          'Where can I find expert insights on this topic?',
          'What practical applications relate to this subject?'
        ],
        citations: []
      });
    }
  }

  /**
   * Executes the article generation process following the proven BaseAgent pattern.
   * @param research - The research data gathered by the Retriever/UI agents.
   * @returns An AgentResponse containing the generated article and follow-up questions.
   */
  async execute(research: ResearchResult): Promise<AgentResponse<ArticleResult>> {
    try {
      if (!research || !research.query) {
        throw new Error('Invalid research data: missing query');
      }
      
      const { query, results = [] } = research;
      
      logger.info('WriterAgent: Starting execution', { 
        query, 
        resultsCount: results.length 
      });

      logger.info('WriterAgent: Preparing source context');
      // Prepare detailed context with full source information for better grounding
      const maxResults = 8; // Increase to 8 most relevant results for better coverage
      const maxContentPerResult = 600; // Increase content length for more comprehensive analysis
      
      const sourceContext = results
        .slice(0, maxResults)
        .map((result: SearchResult, index: number) => {
          const content = 'content' in result 
            ? (result as { content?: string }).content || ''
            : 'snippet' in result 
              ? (result as { snippet?: string }).snippet || ''
              : '';
          const truncatedContent = content.length > maxContentPerResult 
            ? content.slice(0, maxContentPerResult) + '...'
            : content;
          return `Source ${index + 1}:
URL: ${result.url}
Title: ${result.title}
Content: ${truncatedContent}
---`;
        })
        .join('\n\n');

      logger.info('WriterAgent: Making OpenAI API call', { 
        sourceContextLength: sourceContext.length,
        maxResults,
        model: this.defaultModel
      });

      const systemPrompt = `You are an expert research analyst creating comprehensive, well-sourced articles with intelligent follow-up questions.

CRITICAL: You must base your content ONLY on the provided sources. Do not add information not found in the sources.

RESPONSE FORMAT - Return a JSON object with this exact structure:
{
  "content": "Your comprehensive answer here...",
  "followUpQuestions": [
    "Follow-up question 1",
    "Follow-up question 2", 
    "Follow-up question 3",
    "Follow-up question 4",
    "Follow-up question 5"
  ],
  "citations": ["url1", "url2", "url3", "url4", "url5"]
}

CONTENT GUIDELINES:
- Base ALL information directly on the provided sources
- Use [Source X] citations throughout to reference specific sources
- Include specific facts, dates, numbers, and quotes from the sources
- Structure with clear sections using ### headers
- Use **bold** for key terms and *italic* for emphasis
- Synthesize information from multiple sources when they discuss the same topic
- Present different viewpoints when sources conflict
- Maintain professional, informative tone
- Focus on the most current and relevant information from sources
- Do NOT add external knowledge not found in the provided sources

FOLLOW-UP QUESTIONS GUIDELINES:
- Generate 5 intelligent follow-up questions that naturally extend the topic
- Questions should explore deeper aspects, related implications, or practical applications
- Make questions specific and actionable based on the content discussed
- Focus on what readers would logically want to explore next
- Ensure questions build upon the information presented in the article

CITATION REQUIREMENTS:
- Use [Source X] format consistently throughout
- Cite specific claims, statistics, quotes, and facts
- Include multiple citations when information comes from different sources
- Ensure every major point is properly attributed
- List the URLs of cited sources in the citations array`;

      const userPrompt = `Query: "${query}"

Source Material:
${sourceContext}

TASK: Create a comprehensive, well-sourced article that directly addresses the query using ONLY the information provided in the sources above.

Requirements:
- Ground ALL information in the provided sources
- Use [Source X] citations for every major claim or fact
- Include specific details, statistics, dates, and quotes from sources
- Structure with clear sections that organize the information logically
- Generate 5 thoughtful follow-up questions that extend the topic naturally
- Focus on the most current and relevant information available in the sources
- When sources conflict, present different perspectives clearly
- Synthesize related information from multiple sources when appropriate

Remember: Base your response entirely on the source material provided. Do not add external information.`;

      const messages = [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userPrompt }
      ];

      // Add explicit timeout handling for WriterAgent
      const completionPromise = this.callOpenAIViaNetlify(messages, this.defaultModel);
      const timeoutPromise = new Promise<never>((_, reject) =>
        setTimeout(() => reject(new Error('WriterAgent OpenAI call timeout after 30 seconds')), 30000)
      );

      const content = await Promise.race([completionPromise, timeoutPromise]);

      logger.info('WriterAgent: OpenAI call completed', { 
        hasContent: !!content 
      });

      if (!content) {
        throw new Error('No content generated');
      }

      // Parse the JSON response
      let parsed: { content?: string; followUpQuestions?: string[]; citations?: string[] } | null = null;
      try {
        parsed = JSON.parse(content);
      } catch (parseError) {
        logger.warn('JSON parse error:', parseError);
      }

      if (!parsed) {
        // If JSON parsing fails, create a fallback response with follow-up questions
        const fallbackResult: ArticleResult = {
          content: content.trim(),
          followUpQuestions: [
            `What specific developments are shaping ${query} today?`,
            `How are experts addressing challenges in ${query}?`,
            `What practical applications exist for ${query}?`,
            `What future trends are emerging in ${query}?`,
            `How can organizations leverage ${query} effectively?`
          ],
          citations: results.slice(0, 5).map((r: SearchResult) => r.url)
        };
        return {
          success: true,
          data: fallbackResult
        };
      }

      // Ensure the parsed object has the expected structure with follow-up questions
      const result: ArticleResult = {
        content: typeof parsed.content === 'string' ? parsed.content : content.trim(),
        followUpQuestions: Array.isArray(parsed.followUpQuestions) && parsed.followUpQuestions.length > 0 
          ? parsed.followUpQuestions 
          : [
              `What specific developments are shaping ${query} today?`,
              `How are experts addressing challenges in ${query}?`,
              `What practical applications exist for ${query}?`,
              `What future trends are emerging in ${query}?`,
              `How can organizations leverage ${query} effectively?`
            ],
        citations: Array.isArray(parsed.citations) 
          ? parsed.citations 
          : results.slice(0, 5).map((r: SearchResult) => r.url)
      };

      return {
        success: true,
        data: result
      };
    } catch (error) {
      logger.error('WriterAgent execution failed:', error);
      return {
        success: true,
        data: this.getFallbackData(research.query)
      };
    }
  }
}
